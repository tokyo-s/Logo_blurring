{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from torchvision.models import detection\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, default=\"frcnn-resnet\",\n",
    "\tchoices=[\"frcnn-resnet\", \"frcnn-mobilenet\", \"retinanet\"],\n",
    "\thelp=\"name of the object detection model\")\n",
    "ap.add_argument(\"-l\", \"--labels\", type=str, default=\"coco_classes.pickle\",\n",
    "\thelp=\"path to file containing list of categories in COCO dataset\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "\thelp=\"minimum probability to filter weak detections\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device we will be using to run the model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load the list of categories in the COCO dataset and then generate a\n",
    "# set of bounding box colors for each class\n",
    "CLASSES = pickle.loads(open(args[\"labels\"], \"rb\").read())\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary containing model name and its corresponding \n",
    "# torchvision function call\n",
    "MODELS = {\n",
    "\t\"frcnn-resnet\": detection.fasterrcnn_resnet50_fpn,\n",
    "\t\"frcnn-mobilenet\": detection.fasterrcnn_mobilenet_v3_large_320_fpn,\n",
    "\t\"retinanet\": detection.retinanet_resnet50_fpn\n",
    "}\n",
    "# load the model and set it to evaluation mode\n",
    "model = MODELS[args[\"model\"]](pretrained=True, progress=True,\n",
    "\tnum_classes=len(CLASSES), pretrained_backbone=True).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the video stream, allow the camera sensor to warmup,\n",
    "# and initialize the FPS counter\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "\t# grab the frame from the threaded video stream and resize it\n",
    "\t# to have a maximum width of 400 pixels\n",
    "\tframe = vs.read()\n",
    "\tframe = imutils.resize(frame, width=400)\n",
    "\torig = frame.copy()\n",
    "\t# convert the frame from BGR to RGB channel ordering and change\n",
    "\t# the frame from channels last to channels first ordering\n",
    "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\tframe = frame.transpose((2, 0, 1))\n",
    "\t# add a batch dimension, scale the raw pixel intensities to the\n",
    "\t# range [0, 1], and convert the frame to a floating point tensor\n",
    "\tframe = np.expand_dims(frame, axis=0)\n",
    "\tframe = frame / 255.0\n",
    "\tframe = torch.FloatTensor(frame)\n",
    "\t# send the input to the device and pass the it through the\n",
    "\t# network to get the detections and predictions\n",
    "\tframe = frame.to(DEVICE)\n",
    "\tdetections = model(frame)[0]\n",
    "\t# loop over the detections\n",
    "\tfor i in range(0, len(detections[\"boxes\"])):\n",
    "\t\t# extract the confidence (i.e., probability) associated with\n",
    "\t\t# the prediction\n",
    "\t\tconfidence = detections[\"scores\"][i]\n",
    "\t\t# filter out weak detections by ensuring the confidence is\n",
    "\t\t# greater than the minimum confidence\n",
    "\t\tif confidence > args[\"confidence\"]:\n",
    "\t\t\t# extract the index of the class label from the\n",
    "\t\t\t# detections, then compute the (x, y)-coordinates of\n",
    "\t\t\t# the bounding box for the object\n",
    "\t\t\tidx = int(detections[\"labels\"][i])\n",
    "\t\t\tbox = detections[\"boxes\"][i].detach().cpu().numpy()\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\t\t\t# draw the bounding box and label on the frame\n",
    "\t\t\tlabel = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "\t\t\tcv2.rectangle(orig, (startX, startY), (endX, endY),\n",
    "\t\t\t\tCOLORS[idx], 2)\n",
    "\t\t\ty = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "\t\t\tcv2.putText(orig, label, (startX, y),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "\t# show the output frame\n",
    "\tcv2.imshow(\"Frame\", orig)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the 'q' key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\t# update the FPS counter\n",
    "\tfps.update()\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
