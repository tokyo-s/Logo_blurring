{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the the directory where all modules are saved.\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\vladi\\OneDrive\\Desktop\\Sigmoid\\CV\\Object detection\\object detection\\object detection\\utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Importing all needed libraries.\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "from PIL.ExifTags import TAGS, GPSTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    '''\n",
    "        This function is used to create a pretrained FastRCNN Model.\n",
    "    :num_classes: int\n",
    "        The number of classes. Should be setted n+1 wher n is the number of object to detect.\n",
    "    '''\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    #get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train = False):\n",
    "    '''\n",
    "        Uses to create a transformer.\n",
    "    :param train: bool\n",
    "        Decides if to add or not the RandomHorizontalFlip transformation.\n",
    "    '''\n",
    "    transforms = []\n",
    "    # convert the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during the training, randomly flip the trinaing images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1632492310200.jpg',\n",
       " '1632492310204.jpg',\n",
       " '1632492310206.jpg',\n",
       " '1632492310208.jpg',\n",
       " '1632492310209.jpg',\n",
       " '1632492310211.jpg',\n",
       " '1632492366195.jpg',\n",
       " '1632492366197.jpg',\n",
       " '1632492366199.jpg',\n",
       " '1632492366201.jpg',\n",
       " '1632492366204.jpg',\n",
       " '1632492412542.jpg',\n",
       " '1632492412545.jpg',\n",
       " '900px-Times_Square_Panorama.jpg',\n",
       " 'newFile-3.jpg',\n",
       " 'TimesSquare_bright.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\vladi\\OneDrive\\Desktop\\Sigmoid\\CV\\Logo bluring\\images_test')\n",
    "path_dir = os.getcwd()\n",
    "paths = os.listdir()\n",
    "\n",
    "#paths = [r'C:\\Users\\vladi\\OneDrive\\Desktop\\Sigmoid\\CV\\Logo bluring\\images_test\\900px-Times_Square_Panorama.jpg',r'C:\\Users\\vladi\\OneDrive\\Desktop\\Sigmoid\\CV\\Logo bluring\\images_test\\newFile-3.jpg',r'C:\\Users\\vladi\\OneDrive\\Desktop\\Sigmoid\\CV\\Logo bluring\\images_test\\TimesSquare_bright.jpg']\n",
    "for path in paths:\n",
    "    img_path = os.path.join(path_dir,path)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    # Readding the image metadata.\n",
    "    for orientation in TAGS.keys() : \n",
    "        if TAGS[orientation]=='Orientation' : break \n",
    "    # Getting the exif\n",
    "    exif=dict(img.getexif().items())\n",
    "    # Rotating the image if the orientation is wrong.\n",
    "    #         print(img)\n",
    "    #         print(img.getexif())\n",
    "    #print(TAGS.keys())\n",
    "    if len(exif)!=0:\n",
    "        if orientation in exif.keys():\n",
    "            if   exif[orientation] == 3 : \n",
    "                img=img.rotate(180, expand=True)\n",
    "            elif exif[orientation] == 6 : \n",
    "                img=img.rotate(270, expand=True)\n",
    "            elif exif[orientation] == 8 : \n",
    "                img=img.rotate(90, expand=True)\n",
    "                \n",
    "    img = T.Compose([T.ToTensor()])(img,'0')\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = get_model(num_classes=2)\n",
    "loaded_model.load_state_dict(torch.load(r'C:\\Users\\vladi\\OneDrive\\Desktop\\Sigmoid\\CV\\Logo bluring\\logo_detection_model\\fix1_ports_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "# Getting the image.\n",
    "for idx in range(len(imgs)):\n",
    "    img, _ = imgs[idx]\n",
    "    # Getting the object coordinates.\n",
    "#     label_boxes = np.array(test[idx][1]['boxes'])\n",
    "\n",
    "    # Setting the model to eval state.\n",
    "    loaded_model.eval()\n",
    "    # Making the prediction.\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])\n",
    "\n",
    "    # Getting an drawing the image.\n",
    "    image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Drawing the real box around the object.\n",
    "#     for elem in range(len(label_boxes)):\n",
    "#         draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "#                        (label_boxes[elem][2], label_boxes[elem][3])],\n",
    "#                       outline='green', width=3)\n",
    "    # Drawing the predicted box around the object.\n",
    "    for element in range(len(prediction[0]['boxes'])):\n",
    "        boxes = prediction[0]['boxes'][element].cpu().numpy()\n",
    "        score = np.round(prediction[0]['scores'][element].cpu().numpy(), decimals=4)\n",
    "\n",
    "        if score > 0.3:\n",
    "            draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])],\n",
    "                         outline='red', width=3)\n",
    "            draw.text((boxes[0], boxes[1]), text=str(score))\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
